{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒ‡ Welcome to the `loader` module!\n",
    "\n",
    "This is where your urban data journey begins. Whether youâ€™ve got `CSV`, `Parquet`, or `Shapefiles`, weâ€™ll get them loaded up and ready to explore. UrbanMapper provides two main ways to load data:\n",
    "\n",
    "1. **Manual Loading of Local Datasets**: You can load datasets available locally in various formats like CSV, Parquet, and Shapefiles. This is the default approach for working with your own data.\n",
    "2. **Integration with Hugging Face Dataset Library**: UrbanMapper also supports loading datasets from the Hugging Face library via the `from_dataframe()` method. This broadens the possibilities for integrating external data sources seamlessly.\n",
    "\n",
    "**Data source used**:\n",
    "- PLUTO data from NYC Open Data. https://www.nyc.gov/content/planning/pages/resources/datasets/mappluto-pluto-change\n",
    "- Taxi data from NYC Open Data. https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "- **The OSCUR Hugging Face Dataset Source:**\n",
    "The [OSCUR Hugging Face organization](https://huggingface.co/oscur)\n",
    " hosts all datasets associated with [OSCUR](https://oscur.org/): Open-Source Cyberinfrastructure for Urban Computing, a research initiative focused on enabling reproducible, scalable, and accessible data-driven analysis for urban environments.\n",
    "By using the OSCUR datasets, you can skip downloading datasets from Google Drive or official links locally. These datasets are ready to use in all subsequent notebook examples without issue, making your workflow more efficient and seamless.\n",
    "\n",
    "**What youâ€™ll learn**:\n",
    "- How to kick off UrbanMapper.\n",
    "- Loading data from CSV, Parquet, and Shapefile formats.\n",
    "- Loading datasets from Hugging Face with UrbanMapper.\n",
    "\n",
    "Ready? Letâ€™s dive in! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urban_mapper as um\n",
    "\n",
    "# Start up UrbanMapper\n",
    "mapper = um.UrbanMapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CSV Data\n",
    "\n",
    "First up, letâ€™s load a CSV file with PLUTO data. Weâ€™ll tell UrbanMapper where to find the longitude and latitude columns so it knows whatâ€™s what and can make sure those colums are well formatted prior any analysis.\n",
    "\n",
    "Note that below we employ a given csv, but you can put your own path, try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m csv_loader \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmapper\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mloader \u001b[38;5;66;03m# From the loader module\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mfrom_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/[NYC][USA] MapPluto/CSV/pluto.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# To update with your own path\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mwith_columns(longitude_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, latitude_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Inform your long and lat columns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m gdf \u001b[38;5;241m=\u001b[39m csv_loader\u001b[38;5;241m.\u001b[39mload() \u001b[38;5;66;03m# Load the data and create a geodataframe's instance\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# gdf stands for GeoDataFrame, like df in pandas for dataframes.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mapper' is not defined"
     ]
    }
   ],
   "source": [
    "csv_loader = (\n",
    "    mapper\n",
    "    .loader # From the loader module\n",
    "    .from_file(\"../data/[NYC][USA] MapPluto/CSV/pluto.csv\") # To update with your own path\n",
    "    .with_columns(longitude_column=\"longitude\", latitude_column=\"latitude\") # Inform your long and lat columns\n",
    ")\n",
    "\n",
    "gdf = csv_loader.load() # Load the data and create a geodataframe's instance\n",
    "\n",
    "# gdf stands for GeoDataFrame, like df in pandas for dataframes.\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Parquet Data\n",
    "\n",
    "Next, let's grab a `parquet` based dataset for the example. Same workflow as for the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_loader = (\n",
    "    mapper.\n",
    "    loader. # From the loader module\n",
    "    from_file(\"../data/[NYC][USA] Taxi Trips/PARQUET/taxisvis5M.parquet\") # To update with your own path\n",
    "    .with_columns(\"pickup_longitude\", \"pickup_latitude\") # Inform your long and lat columns\n",
    ")\n",
    "\n",
    "gdf = parquet_loader.load() # Load the data and create a geodataframe's instance\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Shapefile Data\n",
    "\n",
    "Finally, letâ€™s load a Shapefile-based dataset. Shapefiles have geometry built in, so no need to specify columns â€” UrbanMapper sorts it out for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_loader = (\n",
    "    mapper\n",
    "    .loader # From the loader module\n",
    "    .from_file(\"../data/[NYC][USA] MapPluto/Shapefile/MapPLUTO.shp\") # To update with your own path\n",
    ")\n",
    "\n",
    "gdf = shp_loader.load() # Load the data and create a geodataframe's instance\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Raster Data\n",
    "\n",
    " Letâ€™s load a Raster file !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RasterLoader.__init__() got an unexpected keyword argument 'latitude_column'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m mapper \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mUrbanMapper()\n\u001b[0;32m      5\u001b[0m rst_loader \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      6\u001b[0m     mapper\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mloader\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mfrom_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../src/urban_mapper/modules/loader/tests/data/lower_manhattan_DEM.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m rst \u001b[38;5;241m=\u001b[39m \u001b[43mrst_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(rst)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\OSCUR\\UrbanMapper\\src\\urban_mapper\\utils\\helpers\\require_attributes.py:32\u001b[0m, in \u001b[0;36mrequire_attributes.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequired attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is an empty list on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\OSCUR\\UrbanMapper\\src\\urban_mapper\\modules\\loader\\loader_factory.py:518\u001b[0m, in \u001b[0;36mLoaderFactory.load\u001b[1;34m(self, coordinate_reference_system)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loader_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatitude_column \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlongitude_column \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    514\u001b[0m ):\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    516\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoader for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_ext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires latitude and longitude columns. Call with_columns() first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    517\u001b[0m     )\n\u001b[1;32m--> 518\u001b[0m loaded_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoordinate_reference_system\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preview \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreview(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preview[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m<@beartype(urban_mapper.modules.loader.loader_factory.LoaderFactory._load_from_file) at 0x208fcbec5e0>:31\u001b[0m, in \u001b[0;36m_load_from_file\u001b[1;34m(__beartype_get_violation, __beartype_conf, __beartype_check_meta, __beartype_func, *args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\OSCUR\\UrbanMapper\\src\\urban_mapper\\modules\\loader\\loader_factory.py:449\u001b[0m, in \u001b[0;36mLoaderFactory._load_from_file\u001b[1;34m(self, coordinate_reference_system)\u001b[0m\n\u001b[0;32m    447\u001b[0m file_ext \u001b[38;5;241m=\u001b[39m Path(file_path)\u001b[38;5;241m.\u001b[39msuffix\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m    448\u001b[0m loader_class \u001b[38;5;241m=\u001b[39m FILE_LOADER_FACTORY[file_ext][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instance \u001b[38;5;241m=\u001b[39m \u001b[43mloader_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatitude_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatitude_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlongitude_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlongitude_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoordinate_reference_system\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoordinate_reference_system\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# Appel gÃ©nÃ©rique, le type de retour dÃ©pend du loader (GeoDataFrame pour tabulaire, dict/array pour raster)\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instance\u001b[38;5;241m.\u001b[39m_load_data_from_file()\n",
      "\u001b[1;31mTypeError\u001b[0m: RasterLoader.__init__() got an unexpected keyword argument 'latitude_column'"
     ]
    }
   ],
   "source": [
    "import urban_mapper as um\n",
    "\n",
    "# Start up UrbanMapper\n",
    "mapper = um.UrbanMapper()\n",
    "rst_loader = (\n",
    "    mapper\n",
    "    .loader\n",
    "    .from_file(\"../../src/urban_mapper/modules/loader/tests/data/lower_manhattan_DEM.tif\")\n",
    ")\n",
    "\n",
    "rst = rst_loader.load()\n",
    "print(rst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from Hugging Face\n",
    "\n",
    "UrbanMapper provides two ways to load datasets from Hugging Face:\n",
    "\n",
    "1. **Using `from_dataframe()`**: This method allows you to load a dataset into a pandas DataFrame first, giving you flexibility to preprocess or explore the data before loading it into UrbanMapper.\n",
    "2. **Using `from_huggingface()`**: This method directly loads the dataset into UrbanMapper, skipping the intermediate DataFrame step for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Using `from_dataframe()`\n",
    "\n",
    "This code loads the \"oscur/pluto\" dataset from Hugging Face, selects the training split, and converts the first 1,000 rows into a pandas DataFrame for efficient analysis and exploration. The resulting DataFrame can then be loaded into UrbanMapper using `from_dataframe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Retrieve the dataset from Hugging Face\n",
    "dataset = load_dataset(\"oscur/pluto\")\n",
    "# Select the training split\n",
    "train_ds = dataset[\"train\"]\n",
    "# Convert the first 1000 rows to a DataFrame\n",
    "df = pd.DataFrame(train_ds[:1000])\n",
    "\n",
    "# Load the dataset using UrbanMapper\n",
    "df_loader = (\n",
    "    mapper\n",
    "    .loader # From the loader module\n",
    "    .from_dataframe(df) # To update with your dataframe\n",
    "    .with_columns(longitude_column=\"longitude\", latitude_column=\"latitude\") # Inform your long and lat columns\n",
    ")\n",
    "\n",
    "gdf = df_loader.load() # Load the data and create a geodataframe's instance\n",
    "\n",
    "# gdf stands for GeoDataFrame, like df in pandas for dataframes.\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Using `from_huggingface()`\n",
    "\n",
    "This method directly loads the \"oscur/pluto\" dataset into UrbanMapper, skipping the intermediate DataFrame step. It's a simpler and faster way to load datasets hosted on Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a full dataset directly from Hugging Face\n",
    "loader = mapper.loader.from_huggingface(\"oscur/pluto\", number_of_rows=100).with_columns(longitude_column=\"longitude\", latitude_column=\"latitude\")\n",
    "gdf = loader.load()\n",
    "gdf  # Next steps: analyze or visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Be Able To Preview Your Loader's instance\n",
    "\n",
    "Additionally, you can preview your loader's instance to see what columns you've specified and the file path you've loaded from. Pretty useful when you load a urban analysis shared by someone else and might want to check what columns are being used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf.preview())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping Up\n",
    "\n",
    "And thatâ€™s that! ðŸŽˆ Youâ€™ve loaded data from four different formats like a pro: `CSV`, `Parquet`, `Shapefile`, and datasets from Hugging Face. Now youâ€™re all set to play with modules like `urban_layer` or `imputer`."
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
=======
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Unexpected error: Level 'DEBUG_LOW' does not exist\n"
     ]
    }
   ],
   "source": [
    "# Integration test for RasterLoader (raster support)\n",
    "from urban_mapper.modules.loader.loader_factory import LoaderFactory\n",
    "\n",
    "# Fake path for a raster file (the file does not need to exist for this test)\n",
    "fake_raster_path = \"test_data/sample.tif\"\n",
    "\n",
    "factory = LoaderFactory()\n",
    "try:\n",
    "    loader = factory.from_file(fake_raster_path)\n",
    "    loader.load()  # Should raise NotImplementedError for now\n",
    "except NotImplementedError as e:\n",
    "    print(\"âœ… RasterLoader recognized, but not yet implemented:\", e)\n",
    "except Exception as ex:\n",
    "    print(\"âŒ Unexpected error:\", ex)\n",
    "else:\n",
    "    print(\"âŒ Error: RasterLoader should have raised NotImplementedError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
>>>>>>> ab0a72a (feat "new example for testing .tiff loading")
   "metadata": {},
   "source": [
    "<h1 style=\"color:black; font-weight:bold;\">Loading Rasters</h1>\n",
    "\n",
    "This cell tests the integration of the new RasterLoader within the LoaderFactory. It attempts to load a raster file (with a fake path) and expects the loader to recognize the raster format and raise a NotImplementedError because the actual raster loading functionality is not yet implemented. The test confirms that the factory correctly dispatches the loading task to the RasterLoader and that the expected exception is raised, indicating the loader is properly integrated but the feature is still under development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
