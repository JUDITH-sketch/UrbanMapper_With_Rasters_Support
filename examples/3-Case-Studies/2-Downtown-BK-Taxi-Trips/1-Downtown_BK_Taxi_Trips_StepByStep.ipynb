{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi Trips Study - Step-by-Step\n",
    "This notebook analyzes taxi trip data, mapping pickups and dropoffs to street segments and visualizing counts.\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "- **[Yellow NYC Taxis 2015](https://arc.net/l/quote/pwljlsqk)**: Sample taxi trip data for NYC.\n",
    "\n",
    "⚠️ Please Note — Within The Documentation's Interactive Examples ⚠️\n",
    "\n",
    "First and foremost, please bear with us; some of our Jupyter Notebooks cannot be interactive and are thus displayed as is in the documentation.  Feel free to install the library and test it out locally.  Next, determine whether they are interactive, which means you can see the output of each cell.  As a result, because it is not a good practice to save datasets in a GitHub (or any other Git in general) repository, we attempted to import urban datasets from `HuggingFace` using `from_huggingface(.)` rather than `from_file(.)`, which would need local file availability.  Nonetheless, this was (1) not always viable (certain datasets are not on `HuggingFace`), and (2) this does not preclude you from using `from_file(.)` or any other available via the API reference's `Loader` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urban_mapper as um\n",
    "\n",
    "# Initialise UrbanMapper\n",
    "mapper = um.UrbanMapper()\n",
    "\n",
    "# Step 1: Create urban layer for street segments\n",
    "layer = (\n",
    "    mapper.urban_layer\n",
    "    .with_type(\"streets_roads\")\n",
    "    .from_place(\"Downtown Brooklyn, New York City, USA\", network_type=\"drive\")\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load taxi trip data\n",
    "# Note: For the documentation interactive mode, we only query 5000 records from the dataset.  Feel free to remove for a more realistic analysis.    \n",
    "data = (\n",
    "    mapper.loader\n",
    "    .from_huggingface(\"oscur/taxisvis1M\", number_of_rows=5000, streaming=True)\n",
    "    .with_columns(longitude_column=\"pickup_longitude\", latitude_column=\"pickup_latitude\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "data['pickup_longitude'] = data['pickup_longitude'].astype(float)\n",
    "data['pickup_latitude'] = data['pickup_latitude'].astype(float)\n",
    "\n",
    "data['dropoff_longitude'] = data['dropoff_longitude'].astype(float)\n",
    "data['dropoff_latitude'] = data['dropoff_latitude'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Impute missing coordinates\n",
    "imputer_pickup = (\n",
    "    mapper.imputer\n",
    "    .with_type(\"SimpleGeoImputer\")\n",
    "    .on_columns(\"pickup_longitude\", \"pickup_latitude\")\n",
    "    .build()\n",
    ")\n",
    "data = imputer_pickup.transform(data, layer)\n",
    "\n",
    "imputer_dropoff = (\n",
    "    mapper.imputer\n",
    "    .with_type(\"SimpleGeoImputer\")\n",
    "    .on_columns(\"dropoff_longitude\", \"dropoff_latitude\")\n",
    "    .build()\n",
    ")\n",
    "data = imputer_dropoff.transform(data, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Filter to bounding box\n",
    "filter_step = mapper.filter.with_type(\"BoundingBoxFilter\").build()\n",
    "data = filter_step.transform(data, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Map pickups and dropoffs\n",
    "import copy\n",
    "tmp_layer = copy.deepcopy(layer)\n",
    "\n",
    "_, mapped_pickups = layer.map_nearest_layer(\n",
    "    data,\n",
    "    longitude_column=\"pickup_longitude\",\n",
    "    latitude_column=\"pickup_latitude\",\n",
    "    output_column=\"pickup_segment\"\n",
    ")\n",
    "\n",
    "_, mapped_dropoffs = tmp_layer.map_nearest_layer(\n",
    "    data,\n",
    "    longitude_column=\"dropoff_longitude\",\n",
    "    latitude_column=\"dropoff_latitude\",\n",
    "    output_column=\"dropoff_segment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Enrich with counts\n",
    "enricher_pickup = (\n",
    "    mapper.enricher\n",
    "    .with_data(group_by=\"pickup_segment\")\n",
    "    .count_by(output_column=\"pickup_count\")\n",
    "    .build()\n",
    ")\n",
    "enriched_layer_pickup = enricher_pickup.enrich(mapped_pickups, layer)\n",
    "\n",
    "enricher_dropoff = (\n",
    "    mapper.enricher\n",
    "    .with_data(group_by=\"dropoff_segment\")\n",
    "    .count_by(output_column=\"dropoff_count\")\n",
    "    .build()\n",
    ")\n",
    "enriched_layer = enricher_dropoff.enrich(mapped_dropoffs, enriched_layer_pickup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Visualize interactively\n",
    "visualiser = (\n",
    "    mapper.visual\n",
    "    .with_type(\"Interactive\")\n",
    "    .with_style({\"tiles\": \"CartoDB dark_matter\", \"colorbar_text_color\": \"white\"})\n",
    "    .build()\n",
    ")\n",
    "fig = visualiser.render(enriched_layer.get_layer(), columns=[\"pickup_count\", \"dropoff_count\"])\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
