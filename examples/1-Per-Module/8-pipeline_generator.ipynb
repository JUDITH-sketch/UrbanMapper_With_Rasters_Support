{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Generator\n",
    "\n",
    "The following notebook shows a nifty Large Language Model (LLM) helper that builds a pipeline from a simple description.\n",
    "\n",
    "Let‚Äôs get generating! üõ†Ô∏è\n",
    "\n",
    "\n",
    "‚ö†Ô∏è Please Note ‚Äî Within The Documentation's Interactive Examples ‚ö†Ô∏è\n",
    "\n",
    "First and foremost, please bear with us; some of our Jupyter Notebooks cannot be interactive and are thus displayed as is in the documentation.  Feel free to install the library and test it out locally.  Next, determine whether they are interactive, which means you can see the output of each cell.  As a result, because it is not a good practice to save datasets in a GitHub (or any other Git in general) repository, we attempted to import urban datasets from `HuggingFace` using `from_huggingface(.)` rather than `from_file(.)`, which would need local file availability.  Nonetheless, this was (1) not always viable (certain datasets are not on `HuggingFace`), and (2) this does not preclude you from using `from_file(.)` or any other available via the API reference's `Loader` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the environment\n",
    "\n",
    "Make sure you have, per the LLM type you would like to use from those available, prepare your environment adequately.\n",
    "For instance, below we will be showcasing gpt-4o. Hence, OPENAI API key is required.\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=\"your-api-key\"\n",
    "```\n",
    "\n",
    "Such API key can be obtained / generated from OPENAI Console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urban_mapper as um\n",
    "\n",
    "# Start UrbanMapper\n",
    "mapper = um.UrbanMapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a User Description\n",
    "\n",
    "Let‚Äôs tell it what we want: mapping PLUTO data to intersections and finding average floors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our urban wish list\n",
    "user_description = \"\"\"\n",
    "I‚Äôve got PLUTO data at './pluto.csv', with 'longitude' and 'latitude' columns.\n",
    "\n",
    "Map this to street intersections in Downtown Brooklyn, New York City, USA, using a 50-metre threshold.\n",
    "\n",
    "Work out the average number of floors per intersection from the 'numfloors' column.\n",
    "\n",
    "The data‚Äôs for all of NYC and might have missing coordinates, so (1) fill in the gaps and (2) filter it to the urban layer‚Äôs bounding box.\n",
    "\n",
    "Show the results on an interactive dark-themed map.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried many user_description such as as:\n",
    "\n",
    "```python\n",
    "user_description = \"\"\"\n",
    "    I have Taxi Trips data from New York City at './taxisvis1M.csv', including two pairs of coordinates latitude, longitude, whihch are: (1) 'pickup_latitude' and 'pickup_longitude, (2) 'dropoff_latitude', and 'dropoff_longitude' columns.\n",
    "    Map this all data to street roads in Downtown Brooklyn, New York City, USA.\n",
    "\n",
    "    Calculate (1) the number of pick ups per street segments, and (2) the number of drop offs per street segments. The data covers all of NYC and contains missing coordinate records, so\n",
    "    (1) handle missing coordinates by excluding those records and (2) filter the data to Downtown Brooklyn‚Äôs bounding box.\n",
    "\n",
    "    Display the results on an interactive dark-themed map, while showing both columns output of interest.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "```python\n",
    "user_description = \"\"\"\n",
    "    I have motor vehicle collision data at './NYC_Motor_Vehicle_Collisions_Mar_12_2025.csv', including 'LATITUDE' and 'LONGITUDE' columns.\n",
    "    Map this data to street intersections in Downtown Brooklyn, New York City, USA.\n",
    "\n",
    "    Calculate the number of collisions per street intersections. The data covers all of NYC and contains missing coordinate records, so\n",
    "    (1) handle missing coordinates by excluding those records and (2) filter the data to Downtown Brooklyn‚Äôs bounding box.\n",
    "\n",
    "    Display the results on an interactive dark-themed map, with collision counts visualized per segment.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "```python\n",
    "user_description = \"\"\"\n",
    "    I have PLUTO data at './pluto.csv', including 'longitude' and 'latitude' columns.\n",
    "    Map this data to street intersections in Downtown Brooklyn, New York City, USA, using a 50-metre threshold.\n",
    "\n",
    "    Calculate the average number of floors per intersection from the 'numfloors' column.\n",
    "    The data covers all of NYC and may have missing coordinates, so (1) impute  missing coordinates and (2) filter it to the urban layer‚Äôs bounding box.\n",
    "\n",
    "    Display the results on an interactive dark-themed map, please.\n",
    "\"\"\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Pipeline\n",
    "\n",
    "Now, let‚Äôs ask the generator to whip up a pipeline for us. We‚Äôll use GPT-4o for the time being.\n",
    "\n",
    "Note that we use Ipython.display to highlight the code in the cell. This is Ipython widget, so it will only work in Jupyter Notebook or Jupyter Lab.\n",
    "\n",
    "The following are the available LLMs primitives:\n",
    "- `gpt-4o`: OpenAI‚Äôs GPT-4o model.\n",
    "- `gpt-4`: OpenAI‚Äôs GPT-4 model.\n",
    "- `gpt-3.5-turbo`: OpenAI‚Äôs GPT-3.5-turbo model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "\n",
    "# Generate pipeline suggestion\n",
    "suggestion = (\n",
    "    mapper\n",
    "    .pipeline_generator # From the pipeline_generator module\n",
    "    .with_LLM(\"gpt-4o\") # With gpt-4o type of LLM\n",
    "    .generate_urban_pipeline(user_description) # Generate the pipeline based on the user description previously instantiated\n",
    ")\n",
    "# print(suggestion)  # See what it suggests (without highlighting)!\n",
    "\n",
    "# Display the suggestion while highlighting the code in the cell\n",
    "Code(suggestion, language=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More LLMs primitives ? Such as Open Source Ones?\n",
    "\n",
    "Wants more? Come shout that out in creating a new issue in the GitHub repo. We‚Äôre all ears! üëÇ\n",
    "\n",
    "https://github.com/VIDA-NYU/UrbanMapper/issues?q=sort%3Aupdated-desc+is%3Aissue+is%3Aopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping Up\n",
    "\n",
    "How fab is that? üåü You‚Äôve got a pipeline suggestion from a quick description. Use it as is or tweak it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
